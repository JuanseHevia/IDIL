{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/juanhevia/IDIL\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "from idil_algs.IDIL.agent.mental_iql import MentalIQL\n",
    "from munch import Munch\n",
    "import yaml\n",
    "import idil_gym\n",
    "from idil_algs.baselines.IQLearn.dataset.expert_dataset import ExpertDataset\n",
    "from idil_algs.baselines.IQLearn.utils.utils import make_env\n",
    "import gym\n",
    "\n",
    "\n",
    "RESULTS_PATH=\"./idil_train/result/\"\n",
    "\n",
    "\n",
    "def load_expert_data_w_labels(demo_path, num_trajs, n_labeled, seed):\n",
    "    expert_dataset = ExpertDataset(demo_path, num_trajs, 1, seed + 42)\n",
    "    print(f'--> Expert memory size: {len(expert_dataset)}')\n",
    "\n",
    "    cnt_label = 0\n",
    "    traj_labels = []\n",
    "    for i_e in range(num_trajs):\n",
    "        if \"latents\" in expert_dataset.trajectories:\n",
    "            expert_latents = expert_dataset.trajectories[\"latents\"][i_e]\n",
    "        else:\n",
    "            expert_latents = None\n",
    "\n",
    "        if i_e < n_labeled:\n",
    "            traj_labels.append(expert_latents)\n",
    "            cnt_label += 1\n",
    "        else:\n",
    "            traj_labels.append(None)\n",
    "\n",
    "    print(f\"num_labeled: {cnt_label} / {num_trajs}, num_samples: \",\n",
    "        len(expert_dataset))\n",
    "    return expert_dataset, traj_labels, cnt_label\n",
    "\n",
    "def compute_sequence_accuracy(pred_latents, true_latents):\n",
    "    pred_latents = np.array(pred_latents)\n",
    "    true_latents = np.array(true_latents)\n",
    "    return np.sum(pred_latents == true_latents) / len(true_latents)\n",
    "\n",
    "# Agent loading\n",
    "\n",
    "def get_run_path(env_name: str, run_id: str):\n",
    "    \"\"\"\n",
    "    Get the path where we store 'model' and 'log' data for a given run\n",
    "    \"\"\"\n",
    "    # read one dir below, as there is always a date directory\n",
    "    _path = os.path.join(RESULTS_PATH, env_name, 'idil', run_id)\n",
    "    _date_folder = os.listdir(_path)[0]\n",
    "    return os.path.join(_path, _date_folder)\n",
    "\n",
    "def get_run_config(run_path:str):\n",
    "    \"\"\"\n",
    "    Parse run YAML configuration and return as Munch dictioanry object\n",
    "    \"\"\"\n",
    "\n",
    "    with open(os.path.join(run_path, 'log', 'config.yaml') , \"r\") as f:\n",
    "        run_conf = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        run_conf = Munch(run_conf)\n",
    "    return run_conf\n",
    "\n",
    "def get_agent(run_path: str, run_conf: Munch):\n",
    "    \"\"\"\n",
    "    Load the agent from the run path\n",
    "    \"\"\"\n",
    "    # load env\n",
    "    env = make_env(run_conf.env_name)\n",
    "\n",
    "    _obs_space_dim = env.observation_space.n if isinstance(env.observation_space, gym.spaces.Discrete) else env.observation_space.shape[0]\n",
    "    _act_space_dim = env.action_space.n if isinstance(env.action_space, gym.spaces.Discrete) else env.action_space.shape[0]    \n",
    "\n",
    "    miql_agent = MentalIQL(config=run_conf,\n",
    "                           obs_dim=_obs_space_dim,\n",
    "                           action_dim=_act_space_dim,\n",
    "                           lat_dim=run_conf.dim_c, # obs dim and action dim are hardcoded for now, they belogn to CleanupSingle\n",
    "                           discrete_obs=isinstance(env.observation_space, gym.spaces.Discrete),\n",
    "                           discrete_act=isinstance(env.action_space, gym.spaces.Discrete))\n",
    "\n",
    "    prefix = os.listdir(os.path.join(run_path, 'model'))[0].split(\"_pi\")[0]\n",
    "\n",
    "    miql_agent.load(os.path.join(run_path, 'model', prefix))\n",
    "    return miql_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actions accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_action_trajectory(expert_dataset, agent):\n",
    "    \"\"\"\n",
    "    Given a precomputed set of latents and states,\n",
    "    run the agent to sample an action and see how the actions differ\n",
    "    \"\"\"\n",
    "\n",
    "    agent_action_trajs = []\n",
    "\n",
    "    for traj_idx in range(len(expert_dataset.trajectories[\"states\"])):\n",
    "        traj_states = expert_dataset.trajectories[\"states\"][traj_idx]\n",
    "        traj_latents = expert_dataset.trajectories[\"latents\"][traj_idx]\n",
    "\n",
    "        _action_traj = []\n",
    "        for _state, _lat in zip(traj_states, traj_latents):\n",
    "            _action = agent.choose_policy_action(_state, _lat)\n",
    "            _action_traj.append(_action)\n",
    "\n",
    "        agent_action_trajs.append(_action_traj)\n",
    "\n",
    "    return agent_action_trajs\n",
    "\n",
    "def compute_action_accuracy(expert_dataset, agent):\n",
    "    \"\"\"\n",
    "    Compute the action accuracy between expert and agent\n",
    "    \"\"\"\n",
    "\n",
    "    agent_action_trajs = backtest_action_trajectory(expert_dataset, agent)\n",
    "\n",
    "    accs = []\n",
    "    for i in range(len(expert_dataset.trajectories[\"states\"])):\n",
    "        _test_acts_expert = np.array(expert_dataset.trajectories[\"actions\"][i])\n",
    "        _test_acts_agent =  np.array(agent_action_trajs[i])\n",
    "\n",
    "        accs.append(np.sum(_test_acts_expert == _test_acts_agent) / len(_test_acts_expert))\n",
    "\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aidil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
