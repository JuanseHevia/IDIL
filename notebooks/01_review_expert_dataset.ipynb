{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/juansegundohevia/Documents/Research/Summer24 RA/IDIL\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "import os\n",
    "dotenv.load_dotenv(dotenv.find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from idil_algs.IDIL.train import load_expert_data_w_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Expert memory size: 134\n",
      "num_labeled: 2 / 3, num_samples:  134\n"
     ]
    }
   ],
   "source": [
    "data_path = \"idil_train/experts/CleanupSingle-v0_100.pkl\"\n",
    "\n",
    "\n",
    "expert_dataset, traj_labels, cnt_label = load_expert_data_w_labels(data_path, 3, 2, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['states', 'next_states', 'actions', 'latents', 'rewards', 'dones', 'lengths'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_dataset.trajectories.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 5, 0, 4, 3]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_dataset.trajectories[\"actions\"][0][:5] # sample actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[27, 0, 9, 9, 9]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_dataset.trajectories[\"states\"][0][:5] # sample actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 3, 3, 3]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_dataset.trajectories[\"latents\"][0][:5] # sample actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory 0:\n",
      "Num. States:  42\n",
      "Num. Actions:  42\n",
      "Num. Latents:  42\n",
      "Trajectory 1:\n",
      "Num. States:  41\n",
      "Num. Actions:  41\n",
      "Num. Latents:  41\n",
      "Trajectory 2:\n",
      "Num. States:  51\n",
      "Num. Actions:  51\n",
      "Num. Latents:  51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5, 5, 2, 5]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "# print shapes of upper level data\n",
    "for idx in range(3):\n",
    "    print(f\"Trajectory {idx}:\")\n",
    "    print(\"Num. States: \", len(expert_dataset.trajectories[\"states\"][idx]))\n",
    "    print(\"Num. Actions: \", len(expert_dataset.trajectories[\"actions\"][idx]))\n",
    "    print(\"Num. Latents: \", len(expert_dataset.trajectories[\"latents\"][idx]))\n",
    "\n",
    "\n",
    "def create_expert_action_policy(dataset):\n",
    "    \"\"\"\n",
    "    Parse state, actions and latent lists and zip into a dictionary where each key is\n",
    "    a tuple of (state, latent) and the values is a list of all actions taken in that state-latent pair.\n",
    "    \"\"\"\n",
    "    states = dataset.trajectories[\"states\"]\n",
    "    actions = dataset.trajectories[\"actions\"]\n",
    "    latents = dataset.trajectories[\"latents\"]\n",
    "\n",
    "    state_latent_actions = defaultdict(list)\n",
    "    for traj_idx in range(len(states)):\n",
    "        assert len(states[traj_idx]) == len(actions[traj_idx]) == len(latents[traj_idx])\n",
    "        _states_idx = states[traj_idx]\n",
    "        _actions_idx = actions[traj_idx]\n",
    "        _latents_idx = latents[traj_idx]\n",
    "\n",
    "        for state, action, latent in zip(_states_idx, _actions_idx, _latents_idx):\n",
    "            state_latent_actions[(state, latent)].append(action)\n",
    "\n",
    "    return state_latent_actions\n",
    "        \n",
    "\n",
    "exp_policy = create_expert_action_policy(expert_dataset)\n",
    "exp_policy[(0,0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'prev_latents'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/juansegundohevia/Documents/Research/Summer24 RA/IDIL/notebooks/01_review_expert_dataset.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/juansegundohevia/Documents/Research/Summer24%20RA/IDIL/notebooks/01_review_expert_dataset.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m expert_dataset\u001b[39m.\u001b[39;49mtrajectories[\u001b[39m\"\u001b[39;49m\u001b[39mprev_latents\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m0\u001b[39m][:\u001b[39m5\u001b[39m] \u001b[39m# sample actions\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'prev_latents'"
     ]
    }
   ],
   "source": [
    "class ExpertPolicySampler:\n",
    "    \"\"\"\n",
    "    Expert policy sampler used for discrete action spaces only.\n",
    "    This creates a dictionary where keys are (state, latent) pairs and provides a \n",
    "    choose_action method to sample uniformly from seen actions in that state-latent pair.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_path, num_trajectories, num_labeled, seed=42):\n",
    "        self.data_path = data_path\n",
    "        self.num_trajectories = num_trajectories\n",
    "        self.num_labeled = num_labeled\n",
    "        self.seed = seed\n",
    "\n",
    "        self.expert_dataset, self.traj_labels, self.cnt_label = load_expert_data_w_labels(data_path, num_trajectories, num_labeled, seed)\n",
    "\n",
    "        self.expert_policy = self._create_expert_policy()\n",
    "\n",
    "    def _create_expert_policy(self):\n",
    "        \"\"\"\n",
    "        Parse state, actions and latent lists from dataset and create a dictionary where \n",
    "        keys are (state, latent) pairs and values are lists of actions taken in that state-latent pair.\n",
    "        \"\"\"\n",
    "        states = self.expert_dataset.trajectories[\"states\"]\n",
    "        actions = self.expert_dataset.trajectories[\"actions\"]\n",
    "        latents = self.expert_dataset.trajectories[\"latents\"]\n",
    "\n",
    "        state_latent_actions = defaultdict(list)\n",
    "        for traj_idx in range(len(states)):\n",
    "            assert len(states[traj_idx]) == len(actions[traj_idx]) == len(latents[traj_idx])\n",
    "            _states_idx = states[traj_idx]\n",
    "            _actions_idx = actions[traj_idx]\n",
    "            _latents_idx = latents[traj_idx]\n",
    "\n",
    "            for state, action, latent in zip(_states_idx, _actions_idx, _latents_idx):\n",
    "                state_latent_actions[(state, latent)].append(action)\n",
    "\n",
    "        return state_latent_actions\n",
    "    \n",
    "    def choose_action(self, state, latent):\n",
    "        \"\"\"\n",
    "        Sample an action from the expert policy given a state and latent.\n",
    "        \"\"\"\n",
    "        return np.random.choice(self.expert_policy[(state, latent)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "activeidil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
